---
title: Docker
icon: devicon:docker
createTime: 2024/12/06 22:40:03
permalink: /en/guide/lwwf78k0/
---

Since our development philosophy focuses on rapid deployment and scalability, Docker is the easiest way to deploy PDATA.
We have already prepared a one-click Docker build script, making the deployment process seamless and hassle-free. I will
now guide you through the steps.

### Install Docker

- Before you begin, make sure that [Docker](https://www.docker.com/)
  and [Docker-Compose](https://docs.docker.com/compose/) are already installed on your machine. If you haven't
  installed them yet, you can visit the Docker Official Website and Docker-Compose Documentation to complete the
  installation.

## Pull the Service Code

- On the [Quick Start](../../guide/quick-start.md) page, you can learn how to obtain our service code and start an instance.

::: tip
In the following guide, all steps will be based on the assumption that `Docker` and `Docker-Compose` have been installed and the corresponding service code has been pulled.
:::

## Main Node Deployment

<ImageCard
image="/SND.png"
title="Main Node Deployment, can also be used as a single node"
description="As the main node, it can control any of the subsequent sub-node machines we expand to. If used as a single node, it will still provide excellent performance as a single-node service."
href="/"
author="yuanshaohang"
date="2024/05/21"
/>

In PDATA, unlike traditional standalone nodes, the main node and sub-nodes in this system are essentially the same, supporting and replacing each other. This means that once you have created a service based on the [Quick Start](../../guide/quick-start.md) guide, the main node is already set up. What you need to focus on now is whether you need to create additional sub-nodes.

## Sub-node Deployment

<ImageCard
image="/Nodes.png"
title="Expand sub-nodes to make the system more highly available, robust, and feature-rich"
description="
The main node manages task files, controls the distribution of tasks to sub-nodes, monitors the resource status of each sub-node, automatically synchronizes task files between master and slave nodes, and enables rapid and convenient development and deployment."
href="/"
author="yuanshaohang"
date="2024/05/21"
/>

If you have already mastered the deployment of the main node, deploying sub-nodes will be even simpler for you, with just one key difference!

::: warning
1. The master and slave nodes can connect with each other.
2. The ports for the worker nodes, 5052 (API) and 8889 (gRPC), are open.
:::
3. 
Start Deployment

- First, navigate to the project root directory, and then execute the script.

```bash
chmod +x reload_server_grpc.sh
sh reload_server_grpc.sh
```

## MySQL Database

You may have noticed that the above steps use MySQL as the database management tool. If you already have an existing MySQL service available, you can directly modify the `setting` configuration in the backend project code to use it.

```python
Mysql = {
    'MYSQL_HOST': 'your host name',
    'MYSQL_DBNAME': 'your dbname',
    'MYSQL_USER': 'your user ',
    'MYSQL_PASSWORD': 'your password',
    'PORT': 'your pory',
}
```

- Execute the SQL file to create the table structure.
- Navigate to the SQL file directory.

```bash
cd data_backend/single_process/my_sql
```

- You can see the following SQL files:
::: file-tree
- my_sql
    - p_cron_info.sql
    - p_data_board.sql
    - p_disk_info.sql
    - p_node_info.sql
    - p_output.sql
    - p_project_info.sql
    - p_quota_info.sql
    - p_SpiderList_monitor.sql
:::

::: tip
Execute the SQL files in sequence to ensure that the table structures have been created in the database.
:::

At this point, you have successfully deployed a main node and a sub-node. To expand to more sub-nodes, simply repeat the same steps (excluding the database setup) on the target machines.
